{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Scikit-learn-01.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python [conda root]",
      "language": "python",
      "name": "conda-root-py"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/RayleighKim/M03_SN_I_Regression/blob/master/Scikit_learn_01.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "1GuUKUnpjb1R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Scikit-Learn 실습 01\n",
        "\n",
        "## Regression Problem\n",
        "### Data set : Bike-sharing dataset, boston-house prices dataset\n",
        "\n",
        "<p style=\"text-align: right;\">\n",
        "Your name :      \n",
        "</p>\n",
        "\n",
        "#### 실습목표<br>\n",
        "1. Pandas 라이브러리로 csv 파일을 불러오고, 전처리할 수 있다.\n",
        "2. Pandas로 전처리한 파일을 Numpy array로 바꿀 수 있다.\n",
        "3. Scikit-learn을 통해 간단히 머신러닝을 사용해볼 수 있다.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "L2nR1VB8jb1S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "matplolib inline 명령어를 통해서\n",
        "matplot으로 그리는 플롯들을 주피터 노트북 내에서 볼 수 있게 해준다.\n",
        "포맷을 retina로 바꾸면 그래프의 화질이 훨씬 좋아진다.\n",
        "'''\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "'''\n",
        "라이브러리들을 불러오자.\n",
        "'''\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "'''\n",
        "사이킷런의 라이브러리들을 미리 불러두는 것도 좋지만,\n",
        "세부적인 메쏘드가 너무 많아서 필요한것만 불러오도록 할 것이다.\n",
        "'''\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zTP9aVTbjb1X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load and Prepare the data"
      ]
    },
    {
      "metadata": {
        "id": "QsToee8-jb1Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_path = 'https://raw.githubusercontent.com/RayleighKim/Example_datasets/master/Bike-Sharing-Dataset/hour.csv'\n",
        "rides = pd.read_csv(data_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dDbUXyTjjb1Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rides.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wOcPM8U3jb1d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "type(rides)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pEqgLwgGjb1f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 참고\n",
        "\n",
        "시간별로 집계한 자전거 sharing 데이터는 지금, rides라는 변수안에 Pandas Dataframe 형태로 저장되어 있다. 간단하게 Pandas를 사용해보자"
      ]
    },
    {
      "metadata": {
        "id": "kcJyG8fYjb1g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rides['instant']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hTQIq5tpjb1i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rides[['instant', 'dteday']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z5Trem4Fjb1l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "columns = ['instant', 'dteday']\n",
        "rides[columns]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tYrtGWyHjb1p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rides[:24]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9wi9Tz9Ejb1s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rides.ix[0:24, [2,5]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QImxNZ0tjb1u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rides[:24*10].plot(x='dteday', y='cnt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j1Lq_AYyjb1y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Dummy Variable\n",
        "\n",
        "Season, weathersit, mnth, hr, weekday 등의 Categorical Variable들은 모델에 넣기 전에 Binary dummy variable로 만들 필요가 있다.\n",
        "\n",
        "그리고 사용하지 않을 변수들은 제거하자.\n",
        "\n",
        "\n",
        "익혀야 할 방법들\n",
        "pd.get_dummies, pd.concat, (Pandas Dataframe).drop"
      ]
    },
    {
      "metadata": {
        "id": "zqkCHy1Ujb1z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dummy_fields = ['season', 'weathersit', 'mnth', 'hr', 'weekday']\n",
        "for each in dummy_fields:\n",
        "    dummies = pd.get_dummies(rides[each], prefix=each, drop_first=False)\n",
        "    rides = pd.concat([rides, dummies], axis=1)\n",
        "\n",
        "fields_to_drop = ['instant', 'dteday', 'season', 'weathersit', \n",
        "                  'weekday', 'atemp', 'mnth', 'workingday', 'hr']\n",
        "data = rides.drop(fields_to_drop, axis=1)\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bzKkkrppjb12",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Scaling target variables\n",
        "\n",
        "mean shifting & Scaling : 평균을 0으로, 표준편차를 1로<br>\n",
        "사실 scikit-learn에서 한방에 하는 방법도 있다.<br>\n",
        "[Missing-Value처리](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Imputer.html), [StandardScaling](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler)<br>\n",
        "연습삼아 직접 해보자!\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "wNy0Kj42jb12",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "quant_features = ['casual', 'registered', 'cnt', 'temp', 'hum', 'windspeed']\n",
        "# Store scalings in a dictionary so we can convert back later\n",
        "scaled_features = {}\n",
        "for each in quant_features:\n",
        "    mean, std = data[each].mean(), data[each].std()\n",
        "    scaled_features[each] = [mean, std]\n",
        "    data.loc[:, each] = (data[each] - mean)/std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6heDm2_bjb14",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "위에서 쓰인 Dictionary 잠깐 짚어보기.\n",
        "Dictionary의 각각의 원소는 key : value 쌍으로 되어 있다.\n",
        "'''\n",
        "\n",
        "scaled_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zVr1UsQcjb16",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Splitting the data into training, testing, and validation sets\n",
        "\n",
        "맨 마지막의 21일을 test_set으로, 그리고 마지막의 81~22 (60일)을 validation set으로, 나머지를 Training set으로 둔다.<br>\n",
        "물론 이것도 [scikit-learn에서 한방](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)에 할 수 있으나 우리는 직접한다!\n",
        "\n",
        "굳이 Validations set을 왜 사용하는지는, 이론만 달리는 날에 신나고 자세하게 달립시다!"
      ]
    },
    {
      "metadata": {
        "id": "2b2Yf3V4jb17",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_data = data[-21*24:]\n",
        "val_data = data[-81*24:-21*24]\n",
        "train_data = data[:-81*24]\n",
        "\n",
        "target_fields = ['cnt', 'casual', 'registered']\n",
        "test_features, test_targets = test_data.drop(target_fields, axis=1), test_data[target_fields]\n",
        "val_features, val_targets = val_data.drop(target_fields, axis=1), val_data[target_fields]\n",
        "train_features, train_targets = train_data.drop(target_fields, axis=1), train_data[target_fields]\n",
        "\n",
        "train_targets.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BUjANbEajb1-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Pandas Dataframe to Numpy array\n",
        "\n",
        "Scikit-learn 만 사용한다면 사실 필요없을 수 있는 과정이다. 하지만, 차후 Tensorflow로 넘어간다면 Numpy를 사용해야만 한다. (Pandas데이터 타입을 받질 못한다.)<br>\n",
        "사실 링크된 Scikit-learn의 문서들을 보면 눈치챘을 수도 있는데, 거의 Numpy하고만 같이 사용되고 있다!<br>\n",
        "[values](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.values.html)라는 방법을 사용할 것이다."
      ]
    },
    {
      "metadata": {
        "id": "bLsfH8Ymjb1-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_features, test_targets = test_features.values, test_targets.values\n",
        "val_features, val_targets = val_features.values, val_targets.values\n",
        "train_features, train_targets = train_features.values, train_targets.values\n",
        "\n",
        "# 우리는 타겟 중 첫번째 컬럼(cnt)만 사용할 것이다.\n",
        "test_cnt = test_targets[:,0]\n",
        "val_cnt = val_targets[:,0]\n",
        "train_cnt = train_targets[:,0]\n",
        "\n",
        "\n",
        "print(train_targets, train_cnt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xag9WL1Ljb2A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model Training\n",
        "\n",
        "이제 데이터가 다 준비가 되었다!\n",
        "\n",
        "해보자! 모델링!"
      ]
    },
    {
      "metadata": {
        "id": "5Ybi0usfjb2B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "단순한 multivariate regression을 해보자!\n",
        "'''\n",
        "import time # 학습시간 측정용\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7vGvK9dkjb2C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 모델 준비\n",
        "simple_regression = linear_model.LinearRegression()\n",
        "\n",
        "# 모델 training\n",
        "# Test셋의 첫번째 컬럼(cnt)만 사용할 것이다. \n",
        "start_time = time.clock()\n",
        "simple_regression.fit(train_features, train_cnt )\n",
        "end_time = time.clock()\n",
        "\n",
        "print('----  {0:.5f}sec, training complete  ----'.format(end_time-start_time))\n",
        "\n",
        "# Training & Validation set에서의 예측값 준비\n",
        "train_pred, val_pred = simple_regression.predict(train_features), simple_regression.predict(val_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qKTFzAYnjb2F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Training & Validation set에서의 성능 확인\n",
        "\n",
        "print(\"Mean Squared Error on Training set : {0:.5f}\".format(mean_squared_error(train_cnt, train_pred)  ))\n",
        "print(\"Mean Squared Error on Validation set : {0:.5f}\".format(mean_squared_error(val_cnt, val_pred)  ))\n",
        "\n",
        "print(\"R-squared Score on Training set : {0:.5f}\".format(r2_score(train_cnt, train_pred)))\n",
        "print(\"R-squared Score on Validation set : {0:.5f}\".format(r2_score(val_cnt, val_pred)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IagHKDOujb2G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Check out on Test set\n",
        "\n",
        "Golden rule : Test set을 모델 학습에 사용하지 말지어다."
      ]
    },
    {
      "metadata": {
        "id": "I_q_3UTBjb2H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "\n",
        "# 예측값도 Scaling 되어 있으므로 그것을 원래대로 되돌려주는 과정\n",
        "mean, std = scaled_features['cnt']\n",
        "simple_predictions = simple_regression.predict(test_features)*std + mean\n",
        "\n",
        "ax.plot(simple_predictions, label = 'Simple_Prediction')\n",
        "ax.plot((test_cnt)*std+mean, label = 'Real')\n",
        "ax.set_xlim(right = len(simple_predictions))\n",
        "ax.legend()\n",
        "\n",
        "dates = pd.to_datetime(rides.ix[test_data.index]['dteday'])\n",
        "dates = dates.apply(lambda d: d.strftime('%b %d'))\n",
        "ax.set_xticks(np.arange(len(dates))[12::24])\n",
        "_ = ax.set_xticklabels(dates[12::24], rotation=45)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sfQcO2sJjb2K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 스스로 실습 01\n",
        "\n",
        "이걸로 끝이 아니다.\n",
        "\n",
        "위와 같은 과정을 싸이킷런의\n",
        "\n",
        "[Support Vector Machine Regression](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html#sklearn.svm.SVR),  [Decision Tree Gression](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor), [K-Nearest Neighbors Regression](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor)\n",
        "\n",
        "에도 적용하고 눈으로 확인해보자! 위 링크의 하단에는 각각 Examples가 있으니 적극활용해보자"
      ]
    },
    {
      "metadata": {
        "id": "Z0ZerrHLjb2K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wJWBVzoUjb2M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dP4Uxk7pjb2O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "위 방식들의 Regression이 끝이 나면 우리는 단순한 뉴럴네트워크를 이용한 Regression으로 넘어간다. [MLPRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor)와 [Neural Network models (supervised)](http://scikit-learn.org/stable/modules/neural_networks_supervised.html)를 적극 참고하자"
      ]
    },
    {
      "metadata": {
        "id": "lVQFH30Kjb2P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "사용한 컬럼의 갯수가 56개이다!\n",
        "'''\n",
        "\n",
        "train_features.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tZlqeLyTjb2R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPRegressor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O4Gv9RFVjb2U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 모델 준비\n",
        "'''\n",
        "히든 레이어의 사이즈를 가지고 놀아보자. 학습하는데 시간을 측정해도 좋다.\n",
        "'''\n",
        "neural_regression = MLPRegressor(hidden_layer_sizes=(32,16,4),\n",
        "                                activation = 'relu',\n",
        "                                solver = 'adam',\n",
        "                                learning_rate_init = 0.0001, #0.00001\n",
        "                                max_iter = 500,\n",
        "                                 random_state=2017\n",
        "                                )\n",
        "\n",
        "# 모델 training\n",
        "# Test셋의 첫번째 컬럼(cnt)만 사용할 것이다. \n",
        "start_time = time.clock()\n",
        "neural_regression.fit(train_features, train_cnt )\n",
        "end_time = time.clock()\n",
        "\n",
        "print('----  {0:.5f}sec, training complete  ----'.format(end_time-start_time))\n",
        "\n",
        "\n",
        "# Training & Validation set에서의 예측값 준비\n",
        "train_pred2, val_pred2 = neural_regression.predict(train_features), neural_regression.predict(val_features)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h3VdjFLQjb2W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Training & Validation set에서의 성능 확인\n",
        "\n",
        "print(\"Mean Squared Error on Training set : {0:.5f}\".format(mean_squared_error(train_cnt, train_pred2)  ))\n",
        "print(\"Mean Squared Error on Validation set : {0:.5f}\".format(mean_squared_error(val_cnt, val_pred2)  ))\n",
        "\n",
        "print(\"R-squared Score on Training set : {0:.5f}\".format(r2_score(train_cnt, train_pred2)))\n",
        "print(\"R-squared Score on Validation set : {0:.5f}\".format(r2_score(val_cnt, val_pred2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CmI6PvgAjb2Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "\n",
        "# 예측값도 Scaling 되어 있으므로 그것을 원래대로 되돌려주는 과정\n",
        "mean, std = scaled_features['cnt']\n",
        "simple_predictions = simple_regression.predict(test_features)*std + mean\n",
        "neural_predictions = neural_regression.predict(test_features)*std + mean\n",
        "\n",
        "#ax.plot(simple_predictions, label = 'Simple_Prediction')\n",
        "ax.plot(neural_predictions, label = 'Neural_Prediction')\n",
        "ax.plot((test_cnt)*std+mean, label = 'Real')\n",
        "ax.set_xlim(right = len(predictions))\n",
        "ax.legend()\n",
        "\n",
        "dates = pd.to_datetime(rides.ix[test_data.index]['dteday'])\n",
        "dates = dates.apply(lambda d: d.strftime('%b %d'))\n",
        "ax.set_xticks(np.arange(len(dates))[12::24])\n",
        "_ = ax.set_xticklabels(dates[12::24], rotation=45)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Te56vzgIjb2h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 스스로 실습 02\n",
        "\n",
        "캐글의 입문 컴페티션중 하나인 Boston House prices 데이터 셋을 가지고 집값을 예측해보자!\n",
        "\n",
        "뉴럴넷을 이용한 회귀모델과, 다른 방식을 이용한 회귀모델을 만들어보자"
      ]
    },
    {
      "metadata": {
        "id": "FFb3UJC_jb2h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_boston\n",
        "boston = load_boston()\n",
        "print(boston.data.shape,  boston.target.shape)\n",
        "'''\n",
        "feature 데이터는 boston.data에\n",
        "target 데이터는 boston.target에 불러와진다.\n",
        "\n",
        "scikit-learn에서는 datasets 안에 미리 연습용 데이터셋을 가지고 있다!\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}